"""\nUtilidades para Learning-to-Rank.\n\n* nDCG calculation\n* Feature extraction helpers\n* Model evaluation metrics\n"""\nimport numpy as np\nfrom typing import List, Tuple\nfrom sklearn.metrics import ndcg_score\n\n\ndef calculate_ndcg(y_true: List[float], y_pred: List[float], k: int = 10) -> float:\n    \"\"\"\n    Calcula Normalized Discounted Cumulative Gain.\n    \n    Args:\n        y_true: Lista de relevâncias reais (0-1 ou 0-5)\n        y_pred: Lista de scores preditos\n        k: Considerar apenas top-k resultados\n    \n    Returns:\n        nDCG@k score (0-1, quanto maior melhor)\n    \"\"\"\n    if len(y_true) != len(y_pred):\n        raise ValueError(\"y_true e y_pred devem ter mesmo tamanho\")\n        \n    if len(y_true) == 0:\n        return 0.0\n        \n    # Converte para numpy arrays\n    y_true_arr = np.array(y_true).reshape(1, -1)\n    y_pred_arr = np.array(y_pred).reshape(1, -1)\n    \n    try:\n        return ndcg_score(y_true_arr, y_pred_arr, k=k)\n    except Exception:\n        return 0.0\n\n\ndef calculate_dcg(relevances: List[float], k: int = None) -> float:\n    \"\"\"\n    Calcula Discounted Cumulative Gain.\n    \"\"\"\n    if k is None:\n        k = len(relevances)\n    k = min(k, len(relevances))\n    \n    dcg = 0.0\n    for i in range(k):\n        dcg += relevances[i] / np.log2(i + 2)\n    \n    return dcg\n\n\ndef calculate_ideal_dcg(relevances: List[float], k: int = None) -> float:\n    \"\"\"\n    Calcula DCG ideal (com relevâncias ordenadas).\n    \"\"\"\n    sorted_relevances = sorted(relevances, reverse=True)\n    return calculate_dcg(sorted_relevances, k)\n\n\ndef precision_at_k(y_true: List[int], y_pred_ranked: List[int], k: int) -> float:\n    \"\"\"\n    Calcula Precision@K.\n    \n    Args:\n        y_true: Lista de relevâncias binárias (0 ou 1)\n        y_pred_ranked: Lista de índices ordenados por predição\n        k: Número de elementos top-k\n    \"\"\"\n    if k <= 0 or len(y_pred_ranked) == 0:\n        return 0.0\n        \n    top_k = y_pred_ranked[:k]\n    relevant_in_top_k = sum(1 for idx in top_k if y_true[idx] == 1)\n    \n    return relevant_in_top_k / k\n\n\ndef mean_reciprocal_rank(y_true: List[int], y_pred_ranked_list: List[List[int]]) -> float:\n    \"\"\"\n    Calcula Mean Reciprocal Rank para múltiplas queries.\n    \"\"\"\n    rr_scores = []\n    \n    for y_true_query, y_pred_ranked in zip(y_true, y_pred_ranked_list):\n        rr = 0.0\n        for rank, idx in enumerate(y_pred_ranked, 1):\n            if y_true_query[idx] == 1:\n                rr = 1.0 / rank\n                break\n        rr_scores.append(rr)\n    \n    return np.mean(rr_scores) if rr_scores else 0.0\n\n\ndef extract_query_features(search_log, impressions) -> Tuple[List[List[float]], List[float]]:\n    \"\"\"\n    Extrai features e labels de uma query específica.\n    \n    Returns:\n        features: Lista de vetores de features para cada impressão\n        labels: Lista de labels (1.0 se clicado, 0.0 caso contrário)\n    \"\"\"\n    features = []\n    labels = []\n    \n    for impression in impressions:\n        # Features extraídas do momento da impressão\n        feature_vector = [\n            impression.sim_semantico,\n            impression.score_confianca, \n            impression.score_avaliacao,\n            impression.score_engajamento,\n            impression.score_proximidade,\n            impression.score_qualificacao,  # Nova feature acadêmica\n        ]\n        \n        # Label: 1.0 se houve clique, 0.0 caso contrário\n        label = 1.0 if hasattr(impression, 'click') else 0.0\n        \n        features.append(feature_vector)\n        labels.append(label)\n    \n    return features, labels